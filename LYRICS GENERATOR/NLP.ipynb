{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "# importing the libraries\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J2JhKeT2vra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6ZhAUaLfWxU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "source": [
        "# preparing the data\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "data = open('rock.txt').read()\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences  \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um40u5k0iDXE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b357e5f8-d7a3-4611-ee3d-e436a15be28c"
      },
      "source": [
        "# model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 151, 100)          352300    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 151, 300)          301200    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 151, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1761)              177861    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3523)              6207526   \n",
            "=================================================================\n",
            "Total params: 7,199,287\n",
            "Trainable params: 7,199,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fef27c24-1e43-48bc-b6c2-297d79d834da"
      },
      "source": [
        "#  training the model\n",
        " history = model.fit(predictors, label, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2939/2939 [==============================] - 90s 30ms/step - loss: 5.6790 - accuracy: 0.0571\n",
            "Epoch 2/10\n",
            "2939/2939 [==============================] - 89s 30ms/step - loss: 5.1726 - accuracy: 0.0960\n",
            "Epoch 3/10\n",
            "2939/2939 [==============================] - 89s 30ms/step - loss: 4.8539 - accuracy: 0.1310\n",
            "Epoch 4/10\n",
            "2939/2939 [==============================] - 89s 30ms/step - loss: 4.5754 - accuracy: 0.1639\n",
            "Epoch 5/10\n",
            "2939/2939 [==============================] - 89s 30ms/step - loss: 4.3241 - accuracy: 0.1920\n",
            "Epoch 6/10\n",
            "2939/2939 [==============================] - 91s 31ms/step - loss: 4.0991 - accuracy: 0.2222\n",
            "Epoch 7/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 3.8852 - accuracy: 0.2544\n",
            "Epoch 8/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 3.6927 - accuracy: 0.2856\n",
            "Epoch 9/10\n",
            "2939/2939 [==============================] - 90s 31ms/step - loss: 3.5131 - accuracy: 0.3155\n",
            "Epoch 10/10\n",
            "2939/2939 [==============================] - 90s 31ms/step - loss: 3.3495 - accuracy: 0.3454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dumv9cugtn5E"
      },
      "source": [
        "model.save('my_model22.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTbrCNGlkDeo",
        "outputId": "193520d7-e6f4-4c10-e5d7-4cb594bbb186"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hJmThBS0R2-"
      },
      "source": [
        "# loading and retraining the model\n",
        "from tensorflow import keras\n",
        "model22 = keras.models.load_model('/content/drive/MyDrive/nlp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_v0GBcia9Xs",
        "outputId": "12f08f51-3265-4736-87c6-b267821d1204"
      },
      "source": [
        "history = model22.fit(predictors, label, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.5630 - accuracy: 0.6856\n",
            "Epoch 2/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.5254 - accuracy: 0.6932\n",
            "Epoch 3/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.5124 - accuracy: 0.6948\n",
            "Epoch 4/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.4907 - accuracy: 0.6994\n",
            "Epoch 5/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.4778 - accuracy: 0.7005\n",
            "Epoch 6/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.4639 - accuracy: 0.7044\n",
            "Epoch 7/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.4534 - accuracy: 0.7036\n",
            "Epoch 8/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.4409 - accuracy: 0.7068\n",
            "Epoch 9/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.4307 - accuracy: 0.7091\n",
            "Epoch 10/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.4238 - accuracy: 0.7097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWc5-feGjpTs",
        "outputId": "e36815dd-5a66-40d0-9cc9-ff0dbd5e8cee"
      },
      "source": [
        "history = model22.fit(predictors, label, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2939/2939 [==============================] - 87s 29ms/step - loss: 1.3284 - accuracy: 0.7251\n",
            "Epoch 2/20\n",
            "2939/2939 [==============================] - 86s 29ms/step - loss: 1.3243 - accuracy: 0.7261\n",
            "Epoch 3/20\n",
            "2939/2939 [==============================] - 86s 29ms/step - loss: 1.3144 - accuracy: 0.7280\n",
            "Epoch 4/20\n",
            "2939/2939 [==============================] - 86s 29ms/step - loss: 1.3153 - accuracy: 0.7283\n",
            "Epoch 5/20\n",
            "2939/2939 [==============================] - 86s 29ms/step - loss: 1.3076 - accuracy: 0.7293\n",
            "Epoch 6/20\n",
            "2939/2939 [==============================] - 87s 29ms/step - loss: 1.3000 - accuracy: 0.7290\n",
            "Epoch 7/20\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.2938 - accuracy: 0.7305\n",
            "Epoch 8/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2840 - accuracy: 0.7328\n",
            "Epoch 9/20\n",
            "2939/2939 [==============================] - 87s 29ms/step - loss: 1.2820 - accuracy: 0.7325\n",
            "Epoch 10/20\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.2787 - accuracy: 0.7336\n",
            "Epoch 11/20\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.2724 - accuracy: 0.7352\n",
            "Epoch 12/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2711 - accuracy: 0.7344\n",
            "Epoch 13/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2635 - accuracy: 0.7359\n",
            "Epoch 14/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2602 - accuracy: 0.7380\n",
            "Epoch 15/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2612 - accuracy: 0.7359\n",
            "Epoch 16/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2447 - accuracy: 0.7403\n",
            "Epoch 17/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2450 - accuracy: 0.7382\n",
            "Epoch 18/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2410 - accuracy: 0.7402\n",
            "Epoch 19/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2393 - accuracy: 0.7399\n",
            "Epoch 20/20\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.2396 - accuracy: 0.7395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsYiWjlWhF_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "683cf215-2eef-4f0d-a545-35c4668786f5"
      },
      "source": [
        "history = model22.fit(predictors, label, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.1702 - accuracy: 0.7493\n",
            "Epoch 2/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.1660 - accuracy: 0.7513\n",
            "Epoch 3/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.1636 - accuracy: 0.7499\n",
            "Epoch 4/10\n",
            "2939/2939 [==============================] - 87s 30ms/step - loss: 1.1600 - accuracy: 0.7507\n",
            "Epoch 5/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1547 - accuracy: 0.7532\n",
            "Epoch 6/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1465 - accuracy: 0.7541\n",
            "Epoch 7/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1572 - accuracy: 0.7507\n",
            "Epoch 8/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1573 - accuracy: 0.7521\n",
            "Epoch 9/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1571 - accuracy: 0.7519\n",
            "Epoch 10/10\n",
            "2939/2939 [==============================] - 88s 30ms/step - loss: 1.1483 - accuracy: 0.7531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot-d6jg5hGB2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI7Oo8-thGEQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHLhSfJXhGHj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTQXmXzmX7Y5"
      },
      "source": [
        "# collecting word stoppers from lyrics\n",
        "data = open('rock.txt').read()\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "def lastWord(string):\n",
        "    newstring = \"\"\n",
        "    length = len(string)\n",
        "    for i in range(length-1, 0, -1):\n",
        "        if(string[i] == \" \"):\n",
        "            return newstring[::-1]\n",
        "        else:\n",
        "            newstring = newstring + string[i]\n",
        "stopwords=[]\n",
        "for i in corpus:\n",
        "  stopwords.append(lastWord(i))\n",
        "improved_stopwords = []\n",
        "for i in stopwords:\n",
        "  try:\n",
        "    if i.lower() not in improved_stopwords:\n",
        "        improved_stopwords.append(i.lower())\n",
        "  except:\n",
        "    if i not in improved_stopwords:\n",
        "        improved_stopwords.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DNPd31FksQC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOoyW8d__Ijr",
        "outputId": "b36ecf72-5c0c-4a8d-9252-9fab4dd9b2ef"
      },
      "source": [
        "stopwordss = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "# genrating new lyrics\n",
        "def generate(x):  \n",
        "  seed_text = x\n",
        "  next_words = 50\n",
        "    \n",
        "  for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    # predicting with the trained model\n",
        "    predicted = model22.predict_classes(token_list, verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == predicted:\n",
        "        output_word = word\n",
        "        break\n",
        "    seed_text += \" \" + output_word\n",
        "  wh=seed_text.split(' ')\n",
        "  for i in wh:\n",
        "    if i in stopwordss:\n",
        "      print(i)\n",
        "      \n",
        "      continue\n",
        "    print(i, end =\" \")  \n",
        "inn=input(' TYPE YOUR STARTING LYRIC')\n",
        "generate(inn)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " TYPE YOUR STARTING LYRICi hate you\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "i\n",
            "hate you\n",
            "they\n",
            "got the\n",
            "doors it's\n",
            "the\n",
            "one that\n",
            "i\n",
            "can't have\n",
            "real love it\n",
            "wasn't enough with\n",
            "you\n",
            "all\n",
            "without me\n",
            "next to\n",
            "you\n",
            "i\n",
            "keep all\n",
            "that\n",
            "we've\n",
            "been\n",
            "low now it's\n",
            "finally sinkin' in\n",
            "a\n",
            "great love like a\n",
            "little kid with\n",
            "glasses in\n",
            "a\n",
            "twin sized bed "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "xcBvZW5gX8SW",
        "outputId": "c4e36092-73bd-49ec-a9ba-0c4b0d6fed28"
      },
      "source": [
        "# saving the model\n",
        "!mkdir NLP\n",
        "model22.save('/content/NLP')\n",
        "\n",
        "\n",
        "!zip -r /content/file.zip /content/NLP\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/NLP/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/NLP/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  adding: content/NLP/ (stored 0%)\n",
            "  adding: content/NLP/keras_metadata.pb (deflated 91%)\n",
            "  adding: content/NLP/assets/ (stored 0%)\n",
            "  adding: content/NLP/variables/ (stored 0%)\n",
            "  adding: content/NLP/variables/variables.data-00000-of-00001 (deflated 57%)\n",
            "  adding: content/NLP/variables/variables.index (deflated 67%)\n",
            "  adding: content/NLP/saved_model.pb (deflated 89%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bf130248-8235-4171-813e-be320cf85fab\", \"file.zip\", 37613735)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL9z-l7dAGnR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRTZZgqC_HsC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nYwZoiXAJEa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}